{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8150e410",
   "metadata": {},
   "source": [
    "# SIGNA Chapter 1 Implementation\n",
    "This notebook implements a single hidden layer ANN, provided that we are given optimal weights, i.e. we don't use backpropagation here just yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a48dc",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn ## Gives us nn.Module()\n",
    "import torch.nn.functional as F # Gives us relu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e8d04",
   "metadata": {},
   "source": [
    "## Implementing a Neural Network.\n",
    "Refer back to the old Java days. An interface is a set role/template that a class can implement. In this case, `nn.Module` is kinda like an interface, but it also is like a superclass, as it has its own default constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601fe8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Kinda like a class default constructor\n",
    "        # Start by calling the superclass constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize the weights and biases\n",
    "        # Usually we get these via backprop\n",
    "        self.w1 = torch.tensor(1.43)\n",
    "        self.b1 = torch.tensor(-0.61)\n",
    "\t\t\t\t\n",
    "        self.w2 = torch.tensor(2.63)\n",
    "        self.b2 = torch.tensor(-0.27)\n",
    "\n",
    "        self.w3 = torch.tensor(-3.89)\n",
    "        self.w4 = torch.tensor(1.35)\n",
    "\n",
    "    def forward(self, input_values):\n",
    "\t\t# Method to run values through our network\n",
    "        # Called by default when we pass input values to an object created with this class\n",
    "        # This implements the prediction math of the neural network\n",
    "        \n",
    "        top_x_axis_values = input_values * self.w1 + self.b1\n",
    "        top_y_axis_values = F.relu(top_x_axis_values)\n",
    "\n",
    "        bottom_x_axis_values = input_values * self.w2 + self.b2\n",
    "        bottom_y_axis_values = F.relu(bottom_x_axis_values)\n",
    "\n",
    "        output_values = top_y_axis_values * self.w3 + bottom_y_axis_values * self.w4\n",
    "        return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de257178-7cca-45d3-aaea-dfb27bfbfce4",
   "metadata": {},
   "source": [
    "## Plug and Chug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c161eddd-88b8-46c4-a84d-6b568a10e125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., -0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an object with the class we just defined\n",
    "model = myNN()\n",
    "\n",
    "# Create some input values\n",
    "input_values = torch.tensor([0.0, 0.5, 1.0])\n",
    "\n",
    "# Run the model (without rounding)\n",
    "# model(input_values)\n",
    "\n",
    "# Optionally, we can round the output values to match the scale we want\n",
    "torch.round(model(input_values), decimals=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
