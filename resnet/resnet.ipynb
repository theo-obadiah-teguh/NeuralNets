{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad30df5-0e4a-4ff0-87f8-f38ce443ced5",
   "metadata": {},
   "source": [
    "# ResNet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f4a89-0447-4d82-8551-4b025940cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init # for Kaiming Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4748d13-2c8e-4404-93ac-b9bbedeb7ecb",
   "metadata": {},
   "source": [
    "## Custom Lambda Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76b500-1407-4992-ad34-7a328a218a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    This layer will be used to implement our skip connections\n",
    "    \"\"\"\n",
    "    def __init__(self, lambd):\n",
    "        \"\"\"\n",
    "        This layer takes a function lambd as an instance variable\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        This method allows the LambdaLayer to transform an input x with the lambd instance variable\n",
    "        Note that layer(x) is the same as layer.forward(x)\n",
    "        \"\"\"\n",
    "        return self.lambd(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6d5ed-99d5-453b-bbb3-dbf97583c22e",
   "metadata": {},
   "source": [
    "## Basic Building Block\n",
    "This BasicBlock design is based on Figure 2 in the original ResNet paper. \n",
    "- A block consists of two weight layers with a ReLU in between.\n",
    "- This is followed by a skip connection summed with the output, and another ReLU.\n",
    "- Each weight layer is a convolution layer followed by batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7feaee-98f5-47ca-9080-0129e5fc80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements the basic building blocks of ResNet.\n",
    "    A building block has two methods:\n",
    "    > __init__() which constructs the block itself\n",
    "    > forward() which explains how inputs are processed by the block.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        \"\"\"\n",
    "        in_channels: the number of planes/filters that this block takes\n",
    "        out_channels: the number of planes/filters that this block outputs\n",
    "        stride: used for downsampling, used only in the first weight layer, in the first BasicBlock of a ResNet layer\n",
    "        \"\"\"\n",
    "        # Call the super class initializer\n",
    "        super().__init__()\n",
    "\n",
    "        # If we use a 3x3 kernel with stride = 1, and maintain in_channel = out_channel, then we need padding = 1\n",
    "        # A fast formula for this is (F - 1) / 2 = (3 - 1) / 2 = 1\n",
    "        # If stride = 2, then this will make out_channel = in_channel / 2\n",
    "        \n",
    "        # Start with the first weight layer\n",
    "        # This is where downsampling MIGHT happen\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                               out_channels=out_channels, \n",
    "                               kernel_size=3, \n",
    "                               stride=stride,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "\n",
    "        # Then make the second weight layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, \n",
    "                               out_channels=out_channels, \n",
    "                               kernel_size=3, \n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "\n",
    "        # Finally, we implement the skip connection for option A (page 4, paragraph 1)\n",
    "        # If there is downsampling, we need to adjust the shape of the input\n",
    "        # Take every two pixels (since we're downsampling by 2 anyway), and add zero padding\n",
    "        # Because the width and height are consistent now, we add out_channels // 4 to the front and back of input\n",
    "        # Therefore, now the width, height, and number of channels are consistent\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.skip = LambdaLayer(lambda x: F.pad(x[:, :, ::2, ::2], \n",
    "                                    pad=(0, 0, 0, 0, out_channels // 4, out_channels // 4),\n",
    "                                    mode=\"constant\",\n",
    "                                    value=0))\n",
    "        # Otherwise, there is no downsampling in the first layer, we don't need to change the shape of the input\n",
    "        else:\n",
    "            self.skip = nn.Sequential() # Just forwards the input as is\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Class method that implements the computation of a BasicBlock.\n",
    "        \"\"\"\n",
    "        # First weight layer\n",
    "        outputs = self.bn1(self.conv1(x))\n",
    "\n",
    "        # Activation with ReLU\n",
    "        outputs = F.relu(outputs)\n",
    "\n",
    "        # Second weight layer and join the skip connection\n",
    "        outputs = self.bn2(self.conv2(outputs))\n",
    "        outputs += self.skip.forward(x)\n",
    "\n",
    "        # Activation with ReLU\n",
    "        outputs = F.relu(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd86e6e-8a5c-4493-80a7-eff0df0685e7",
   "metadata": {},
   "source": [
    "## Kaiming Normal Initialization\n",
    "The paper mentions that weight initialization follows that of \"K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In ICCV, 2015.\"\n",
    "\n",
    "How does `model.apply(_weights_init)` work?\n",
    "> When you call `model.apply(_weights_init)`, PyTorch starts at the top-level model.\n",
    "It then goes through every single submodule inside model, one by one.\n",
    "For each submodule it encounters (let's call it m), it calls the function `_weights_init(m)`, passing that specific submodule m as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78174705-4a58-40e4-b02a-5fe11cf289b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weights_init(m: nn.Module):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfa684-093d-4368-a9ad-d4ae470cdb4d",
   "metadata": {},
   "source": [
    "## ResNet Class\n",
    "Based on the original paper, at Section 4.2 CIFAR-10 and Analysis (Para. 1), the inputs are 32x32 RGB images (i.e. 3 filters/channels/planes) with per-pixel mean subtracted. Moreover, the chosen architecture is as follows. **Note that n is the number of BasicBlock objects in a ResNet layer.**\n",
    "1. The first layer is a 3x3 kernel convolution, with feature (output) map size 32x32, with 16 channels. (This is `self.conv` and `self.bn`)\n",
    "2. The next 2n layers has feature (output) map size 32x32, 16 channels. (We call this `self.layer1`)\n",
    "3. The next 2n layers has feature (output) map size 16x16, 32 channels. (We call this `self.layer2`)\n",
    "4. The final 2n layers has feature (output) map size 8x8, 64 channels. (We call this `self.layer3`)\n",
    "5. The network ends with a global average pooling, a 10-way fully-connected layer, and softmax. (This is `self.linear`)\n",
    "\n",
    "Why does a BasicBlock contribute 2n towards the total number of layers?\n",
    "> It's because each BasicBlock comprises of two conv-bn pairs.\n",
    "\n",
    "Why don't we need SoftMax in `forward()`?\n",
    "> It's because we are using cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c7f52-cf1d-4657-baea-ff68f5322044",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10): # For CIFAR-10, we have 10 output classes\n",
    "        super().__init__()\n",
    "\n",
    "        # If we want to use a 3x3 kernel with stride = 1, and maintain a 32x32 output, then we need padding = 1\n",
    "        # A fast formula for this is (F - 1) / 2 = (3 - 1) / 2 = 1\n",
    "        self.conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(num_features=16) # num_features = out_channels from previous layer\n",
    "\n",
    "        # This instance variable will be used for the ResNet layers\n",
    "        # This is consistent with the above convolution and batch normalization output\n",
    "        self.in_channels = 16\n",
    "        \n",
    "        # Stride = 1, because feature map (output) size of this layer is 32x32\n",
    "        self.layer1 = self._make_layer(block, num_blocks[0], out_channels=16, stride=1)\n",
    "\n",
    "        # Stride = 2, because feature map (output) size of this layer is 16x16\n",
    "        self.layer2 = self._make_layer(block, num_blocks[1], out_channels=32, stride=2)\n",
    "\n",
    "        # Stride = 2, because feature map (output) size of this layer is 8x8\n",
    "        self.layer3 = self._make_layer(block, num_blocks[2], out_channels=64, stride=2)\n",
    "\n",
    "        # After global average pooling, the 8x8x64 tensors will be squashed into a 64-dimensional vector\n",
    "        # That vector will be the input to this linear transformation\n",
    "        self.linear = nn.Linear(in_features=64, out_features=num_classes)\n",
    "\n",
    "        # Initialize weights for convolutional and fully connected layers\n",
    "        # This recursively goes through all the submodules\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, num_blocks, out_channels, stride):\n",
    "        \"\"\"\n",
    "        Constructs a ResNet layer comprising of building blocks.\n",
    "        \"\"\"\n",
    "        # If a layer does downsampling, it's done in the first block\n",
    "        # The other blocks have stride=1 so that the feature map sizes don't decrease anywhere else\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "\n",
    "        # Create the blocks\n",
    "        blocks = []\n",
    "        for stride in strides:\n",
    "            # Example: input is 32x32, 16 channels, we want to output 16x16, 8 channels\n",
    "            # We have 3 blocks, then Block 1 will have 16 channels as input, 8 channels as output, stride = 2\n",
    "            # Block 2 will have 8 channels as input, and 8 channels as output, stride = 1\n",
    "            # Block 3 will have 8 channels as input, and 8 channels as output, stride = 1\n",
    "            blocks.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "\n",
    "        # Stack the blocks into a sequential layer, using Python list unpacking\n",
    "        return nn.Sequential(*blocks) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Class method that implements the computation of a ResNet.\n",
    "        \"\"\"\n",
    "        # Part 1\n",
    "        output = F.relu(self.bn(self.conv(x)))\n",
    "\n",
    "        # Part 2 - 4\n",
    "        output = self.layer1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "\n",
    "        # Part 5\n",
    "        # The previous passed output is [batch, 64, 8, 8]\n",
    "        # Recall the shape [batch, channels, height, width]\n",
    "        output = F.avg_pool2d(output, kernel_size=output.size()[3])\n",
    "\n",
    "        # The pooling layer created a tensor of size [batch, 64, 1, 1], technically a 64-D vector\n",
    "        # Now we flatten the tensor into a vector\n",
    "        output = torch.flatten(output, 1) # flattens from idx 1 onwards\n",
    "\n",
    "        # Throw it into the feedforward network\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6584f",
   "metadata": {},
   "source": [
    "## Factory Functions for Fast Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746be5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet20(): # n = 3\n",
    "    # The ResNet has a single conv layer to start with\n",
    "    # Then here we specify each ResNet layer has 3 BasicBlocks\n",
    "    # And one final fully connected layer\n",
    "    # So the total is 1 + (2 x 3) x 3 + 1 = 20\n",
    "    return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "\n",
    "def resnet32(): # n = 5\n",
    "    # The ResNet has a single conv layer to start with\n",
    "    # Then here we specify each ResNet layer has 5 BasicBlocks\n",
    "    # And one final fully connected layer\n",
    "    # So the total is 1 + (2 x 5) x 3 + 1 = 32\n",
    "    return ResNet(BasicBlock, [5, 5, 5])\n",
    "\n",
    "\n",
    "def resnet44(): # n = 7\n",
    "    # The ResNet has a single conv layer to start with\n",
    "    # Then here we specify each ResNet layer has 7 BasicBlocks\n",
    "    # And one final fully connected layer\n",
    "    # So the total is 1 + (2 x 7) x 3 + 1 = 44\n",
    "    return ResNet(BasicBlock, [7, 7, 7])\n",
    "\n",
    "\n",
    "def resnet56(): # n = 9\n",
    "    # The ResNet has a single conv layer to start with\n",
    "    # Then here we specify each ResNet layer has 9 BasicBlocks\n",
    "    # And one final fully connected layer\n",
    "    # So the total is 1 + (2 x 9) x 3 + 1 = 56\n",
    "    return ResNet(BasicBlock, [9, 9, 9])\n",
    "\n",
    "\n",
    "def resnet110(): # n = 18\n",
    "    # The ResNet has a single conv layer to start with\n",
    "    # Then here we specify each ResNet layer has 18 BasicBlocks\n",
    "    # And one final fully connected layer\n",
    "    # So the total is 1 + (2 x 18) x 3 + 1 = 110\n",
    "    return ResNet(BasicBlock, [18, 18, 18])\n",
    "\n",
    "\n",
    "def resnet1202(): # n = 200\n",
    "    # The ResNet has a single conv layer to start with\n",
    "    # Then here we specify each ResNet layer has 200 BasicBlocks\n",
    "    # And one final fully connected layer\n",
    "    # So the total is 1 + (2 x 200) x 3 + 1 = 1202\n",
    "    return ResNet(BasicBlock, [200, 200, 200])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
